{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzfWamILVqcH"
      },
      "source": [
        "##Step 1: Installing Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSDxvXsTWg-Y",
        "outputId": "e7224f0e-5d82-479b-92b8-5df7d443fa2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets\n",
        "!pip install pytorch-lightning\n",
        "!pip install -q git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMjwzYJIW8Jk"
      },
      "source": [
        "##Step 2: Importing Libraries and Setting Up Environment\n",
        "This step imports the necessary libraries and sets up the environment for the project.\n",
        "#Importing Libraries\n",
        "In this step, essential libraries are imported for data manipulation (pandas, numpy), random operations (random, math), deep learning with PyTorch (torch, torch.nn), loading datasets (load_dataset), data splitting and evaluation metrics (train_test_split, f1_score, roc_auc_score, accuracy_score), and working with pre-trained models and training utilities from the Transformers library (AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer).\n",
        "\n",
        "#Setting Up Environment\n",
        "A random state (state = 42) is set for reproducibility.\n",
        "Seeds are set for PyTorch, NumPy, and random number generators to ensure consistent results across runs.\n",
        "torch.backends.cudnn.enabled and torch.backends.cudnn.deterministic are set to control the deterministic behavior of CUDA operations.\n",
        "The set_seed function from transformers is used to set a consistent seed for the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "KidDlSJRwlzl",
        "outputId": "a9fe45d6-ef9b-4084-acbc-d7336a136e66"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import EvalPrediction\n",
        "\n",
        "state = 42\n",
        "torch.manual_seed(state)\n",
        "torch.cuda.manual_seed(state)\n",
        "np.random.seed(state)\n",
        "random.seed(state)\n",
        "torch.backends.cudnn.enabled=False\n",
        "torch.backends.cudnn.deterministic=True\n",
        "\n",
        "from transformers import set_seed\n",
        "set_seed(42)\n",
        "\n",
        "#This step is optional and may be skipped if not running on Google Colab or if not using Google Drive for data storage.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #This line is specific to Google Colab and mounts the user's Google Drive to the notebook environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvDNQ-dfZTrD"
      },
      "source": [
        "##Step 3: Loading Dataset\n",
        "This step loads the dataset for training and evaluation. The code provides two options for loading the dataset: using the entire dataset or using pre-split data for training, testing, and validation.\n",
        "<br>The load_dataset function from the Hugging Face datasets library allows you to easily load and access various datasets for machine learning tasks, supporting multiple data formats and efficient caching.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeUfvH5bZi_8"
      },
      "outputs": [],
      "source": [
        "# Option 1: Using the entire dataset for training\n",
        "dataset = load_dataset('csv', data_files={'train': ['/content/drive/MyDrive/projects/finetuning_LLMs_with_MIRTE_data/data/cleaned_data_for_multiclassification_task/cleaned_shuffled_new_MITRE.csv',],\n",
        "                                          })\n",
        "\n",
        "# Option 2: Using pre-split data for training, testing, and validation\n",
        "# dataset = load_dataset('csv', data_files={'train': ['/content/drive/MyDrive/projects/finetuning_LLMs_with_MIRTE_data/data/cleaned_data_for_multiclassification_task/splited_data_into_train_test_val/cleaned_MITRE_data_trainset.csv',],\n",
        "#                                           'test': ['/content/drive/MyDrive/projects/finetuning_LLMs_with_MIRTE_data/data/cleaned_data_for_multiclassification_task/splited_data_into_train_test_val/cleaned_MITRE_data_testset.csv',],\n",
        "#                                           'validation': ['/content/drive/MyDrive/projects/finetuning_LLMs_with_MIRTE_data/data/cleaned_data_for_multiclassification_task/splited_data_into_train_test_val/cleaned_MITRE_data_valset.csv',]\n",
        "#                                           })\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdDQcXAlbfjh"
      },
      "source": [
        "##Step 4: Creating Label Mappings\n",
        "This step creates a list of labels and two dictionaries for mapping labels to integers and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4imOJV8SbCYX"
      },
      "outputs": [],
      "source": [
        "labels = [label for label in dataset['train'].features.keys() if label not in ['ID', 'Description']]\n",
        "labels = sorted(labels)\n",
        "id2label = {idx:label for idx, label in enumerate(labels)}\n",
        "label2id = {label:idx for idx, label in enumerate(labels)}\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSncynG1dmWu"
      },
      "source": [
        "##Step 5: Preprocessing Data\n",
        "\n",
        "\n",
        "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
        "<br> In this cell, we can choose which tokenizer to use (roberta-base, roberta-large, or SecureBERT).\n",
        "<br>What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hECA6jibzqS"
      },
      "outputs": [],
      "source": [
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ehsanaghaei/SecureBERT\")\n",
        "\n",
        "def preprocess_data(examples):\n",
        "  # take a batch of texts\n",
        "  text = examples[\"Description\"]\n",
        "  # encode them\n",
        "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512)\n",
        "  # add labels\n",
        "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
        "  # create numpy array of shape (batch_size, num_labels)\n",
        "  labels_matrix = np.zeros((len(text), len(labels)))\n",
        "  # fill numpy array\n",
        "  for idx, label in enumerate(labels):\n",
        "    labels_matrix[:, idx] = labels_batch[label]\n",
        "\n",
        "  encoding[\"labels\"] = labels_matrix.tolist()\n",
        "\n",
        "  return encoding\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRifS4jAgBf0"
      },
      "source": [
        "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrDVYVJGfyms"
      },
      "outputs": [],
      "source": [
        "encoded_dataset.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "210x4vgtgGif"
      },
      "source": [
        "##Step 6: Define model\n",
        "\n",
        "Here we define a model that includes a pre-trained base (i.e. the weights from SecureBERT) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
        "\n",
        "This is also printed by the warning.\n",
        "\n",
        "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uQOD9engmu1"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"ehsanaghaei/SecureBERT\",\n",
        "                                                           problem_type=\"multi_label_classification\",\n",
        "                                                           num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80dN3bsog9vB"
      },
      "source": [
        "##Step 7: Train the model!\n",
        "\n",
        "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things:\n",
        "\n",
        "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
        "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7YdGhFQ9O2f"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "metric_name = \"f1\"\n",
        "\n",
        "#Option 1: Training without Evaluation\n",
        "#This option is for training the model without performing any evaluation during the training process\n",
        "args = TrainingArguments(\n",
        "    f\"roberta-finetuned\",\n",
        "    evaluation_strategy = \"no\",\n",
        "    do_eval=False,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=30,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "#Option 2: Training with Evaluation\n",
        "#This option is for training the model with evaluation performed at the end of each epoch.\n",
        "\n",
        "# args = TrainingArguments(\n",
        "#     f\"roberta-finetuned\",\n",
        "#     evaluation_strategy = \"epoch\",\n",
        "#     save_strategy = \"epoch\",\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=batch_size,\n",
        "#     per_device_eval_batch_size=batch_size,\n",
        "#     num_train_epochs=12,\n",
        "#     weight_decay=0.01,\n",
        "#     load_best_model_at_end=True,\n",
        "#     metric_for_best_model=metric_name,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn9NciVBidyr"
      },
      "source": [
        "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md48-Teb9O4u"
      },
      "outputs": [],
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # return as dictionary\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ9zaeLGjFhT"
      },
      "outputs": [],
      "source": [
        "#if we want to evaluate our traing with val or test set we can uncomment eval_dataset, and compute_metrics\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    #eval_dataset=encoded_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    #compute_metrics=compute_metrics,\n",
        "    )\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIufGkQ5jVgF"
      },
      "outputs": [],
      "source": [
        "#Save the fine-tuned model in the desired output directory.\n",
        "\n",
        "trainer.save_model('/content/drive/MyDrive/finetuned/secure_bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRxHaao3lGYY"
      },
      "outputs": [],
      "source": [
        "#if we use test or eval set we can use this line of code for evaluation\n",
        "#trainer.evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
